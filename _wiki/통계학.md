---
layout: wiki 
title: 통계학
last-modified: 2020/01/02
---

<!-- TOC -->

- [통계의 정의](#통계의-정의)
- [통계학의 종류](#통계학의-종류)
- [통계 용어](#통계-용어)
    - [가설 검정<sup>hypothesis test</sup>](#가설-검정hypothesis-test)
        - [가설검정 이용하기<sup>Using Hypothesis Tests</sup>](#가설검정-이용하기using-hypothesis-tests)
    - [중심 극한 정리<sup>central limit theorem</sup>](#중심-극한-정리central-limit-theorem)
    - [상관 분석](#상관-분석)
        - [상관 계수<sup>correlation coefficient</sup>](#상관-계수correlation-coefficient)
    - [거짓 상관](#거짓-상관)
        - [잠재 변수<sup>latent variables</sup>를 간파할 수 있는가?](#잠재-변수latent-variables를-간파할-수-있는가)
    - [부트스트래핑<sup>Bootstrapping</sup>](#부트스트래핑bootstrapping)
    - [편찻값](#편찻값)
    - [회귀<sup>regression</sup>](#회귀regression)
    - [편향<sup>bias</sup>](#편향bias)
    - [실험 계획법](#실험-계획법)
    - [기타](#기타)
- [분포](#분포)
- [평균의 종류](#평균의-종류)
    - [조화 평균](#조화-평균)
- [Books](#books)
    - [통계학을 떠받치는 일곱기둥 이야기 <sub>2016</sub>](#통계학을-떠받치는-일곱기둥-이야기-2016)
    - [좋은 선택, 나쁜 선택 <sub>2019</sub>](#좋은-선택-나쁜-선택-2019)

<!-- /TOC -->

# 통계의 정의
통계: 데이터로 부터 분포의 특징이나 반복되는 것을 이끌어 내기 위한 방법  
통계 - 축약 <sup>summary</sup> - 통계량  
(통계학 입문, 2009)

# 통계학의 종류
- 추측(추리) 통계학 <sup>stochastic</sup>은 추계학으로 불리며, 빈도론적 통계학과 베이즈 통계학이 있다.
<img src="https://user-images.githubusercontent.com/1250095/45733500-fb3cba00-bc1b-11e8-8f3f-75369a0bf2c2.jpeg" width="70%" />  
(통계학 도감, 2017)

- 기술 통계학 <sup>descriptive statistics</sup>  
여기서 말하는 기술은 technology가 아니라 descriptive다. 즉, '기술하다'의 기술을 말하며 다양한 시각화 등이 여기에 포함된다.

# 통계 용어
- 표준 편차<sup>standard deviation, stddev, SD</sup>는 분산의 제곱근으로, 분산<sup>variance</sup>은 거리 제곱의 평균: 평균값 주변에 어느 정도 넓게 퍼져 있는가를 뜻하며 가장 중요 (통계학 입문, 2009)
- 표준 점수<sup>standard score</sup>는 표준 편차의 배수로 z-score로 부른다.
- [표준 오차<sup>standard error, stderr, SE</sup>에 대한 설명](http://brachymystax.blogspot.kr/2010/03/blog-post_05.html)
    - 평균의 표준오차<sup>standard error of the mean</sup> = 표준 편차/sqrt{표본 크기}, 아래는 표본수에 따른 표준오차의 변화를 나타냈다.    
<img src="https://user-images.githubusercontent.com/1250095/34705268-a9d5d0de-f542-11e7-85f3-6e71bcf78aff.jpeg" width="50%" />
    
- 비율의 표준오차  
    
<img src="https://user-images.githubusercontent.com/1250095/34705269-aa106960-f542-11e7-8492-082cd31afeb4.jpeg" width="45%" /><img src="https://user-images.githubusercontent.com/1250095/34705270-aa3547c6-f542-11e7-8665-8e4bb45c846d.jpeg" width="45%" />  
     
'p-value가 5%를 밑도는가 하는 유의수준으로 가설검정<sup>hypothesis test</sup>하여 출세율이 16.3%라는 가설 ~ 출세율이 25.7%라는 가설은 부정할 수 없다'라고 말할 수 있다. 이 비율과 평균값+-2SE라는 가장 자주 사용되는 신뢰구간은 5%의 유의수준이고 부정할 수 없는 가설 범위라는 의미로 특별히 **95% 신뢰구간**이라고 부른다. (통계의 힘 2, 2014)

- 신뢰구간<sup>confidence interval</sup>=표본평균+-신뢰도상수*표준오차
- 대립가설<sup>alternative hypothesis</sup>은 우리가 증명하고자 하는 명제
- 귀무가설<sup>null hypothesis</sup>은 우리가 부정하려는 명제. 귀무 가설은 '우연으로 인한 데이터'로 결과는 우연 때문이라 가정한다.
    - **귀무가설 <sup>null hypothesis</sup>이 성립한다는 가정 아래 데이터가 얻어지는 확률을 p-value라고 한다.**
        - '까마귀가 검은지 하얀지가 반반인 경우(귀무가설) 100번 연속으로 검은 까마귀가 발견되었다'는 관찰 결과가 얻어지는 확률의 1조분의 1보다 작다는 것이 p-value이다. (통계의 힘 2, 2014)
    - 어느 정도 p-value가 작아야 '존재할 수 없다'고 생각하는지의 기준은 5%를 경계선으로 하는데, 위대한 통계학자 피셔가 일찍이 'p-value를 5%로 판단하는 것이 편리하다'는 글을 남긴 것이 계기다. (통계의 힘, 2013) p-value가 5% 이하 일때 null hypothesis를 기각하고 significance <sup>유의</sup>하다고 판단한다.
    
- 제1종($$\alpha$$) 오류<sup>type I error</sup> 아무 차이가 없는데도 차이가 있는 것으로 인식시키는 실수(귀무가설을 잘못 기각하는 오류)
    - 제1종 오류 허용 수준을 가리켜 유의수준<sup>level of significance</sup>이라 부른다.
- 제2종($$\beta$$) 오류<sup>type II error</sup> 본래 차이가 존재하는데도 그것을 못 보고 놓쳐버리는 실수(귀무가설을 잘못 채택하는 오류)
- 통계적 추론<sup>statistical inference</sup>은 데이터 분석을 통해 기본 확률 분포의 특성을 추론하는 프로세스다.

『통계의 힘』 저자는 **임의화 비교실험**<sup>randomized experiment</sup>을 유난히 강조한다. *lady tasting tea*는 피셔가 진행한 세계 최초로 이루어진 임의화 비교실험이었다. 그러나 '현실, 윤리, 감정'의 한계가 있다.

## 가설 검정<sup>hypothesis test</sup>
- **Student's t-test<sup>t 검정</sup>** 수십 건 정도의 작은 데이터로도 정확하게 z 검정을 할 수 있으며, 수백에서 수천 건의 데이터가 있을 경우 t 검정과 z 검정의 결과는 일치한다.
- **Fisher's exact test<sup>피셔의 정확 검정</sup>** '조합의 수'를 사용하여 수십 건 정도의 데이터로도 정확하게 비율의 차이에 의미가 있는지를 알기 위해 p-value를 구한다.
- **Chi-squared test<sup>카이제곱검정</sup>** 구글의 세르게이 브린은 '장바구니 분석보다 통계학적 상관분석이 낫다'는 내용의 논문을 발표한 바 있다. 장바구니 분석에서는 개선도나 지지도를 보면서 이것저것 검토해야 하지만, 카이제곱값을 사용했다면 오차에 휘둘리지 않고 관련성이 강한 상품 조합을 자동적으로 찾을 수 있다. 아마존에서도 상품 추천에 이러한 상관분석을 이용한다. (통계의 힘, 2013) 정규 분포를 따르는 여러 데이터를 한꺼번에 취급할 수 있어, 분산분석에 이용할 수 있다. (통계학 도감, 2017)

### 가설검정 이용하기<sup>Using Hypothesis Tests</sup>
1. 검정할 가설을 결정합니다. Decide on the hypothesis  
null hypothesis를 사실이라고 가정하고 반하는 증거가 발견될 경우 기각하고 alternative hypothesis(`H_1:p < 0.9`, 책 기준)를 채택한다.
1. 검정통계를 선택합니다. Choose your test statistic
1. 기각역을 정합니다. Determine the critical region  
우선 유의수준 <sup>significance level</sup>을 정할 필요가 있으며, 일반적으로 피셔의 방식에 따라 5%로 정한다.
1. 검정통계를 위한 p-value를 찾습니다. Find the p-value
1. 표본결과가 기각역 안에 들어오는지 확인합니다. Is the sample result in the critical region?
1. 결정을 내립니다. Make your decision

(Head First Statistics, 2008)

## 중심 극한 정리<sup>central limit theorem</sup>
라플라스가 얻어낸 결과인 중심 극한 정리<sup>central limit theorem</sup>는 확률과 통계 분야에서 중요한 전환점이 되었는데, 관측 오차들을 분석하는 데 수학자들이 가장 좋아하는 분포, 즉 종형 곡선을 사용할 수 있는 이론적 근거를 제공했기 때문이다. (세계를 바꾼 17가지 방정식, 2011) 

몇 가지 사건이 서로에게 관계 없이(독립적으로) 일어날 때 사건의 수가 많으면 그들 사건의 합이나 평균의 확률 분포는 정규 분포가 된다(중심 극한 정리). (통계와 확률의 원리, 2017)

## 상관 분석
<img src="https://user-images.githubusercontent.com/1250095/34091496-5052660a-e401-11e7-8994-1bb66a130e1b.jpeg" width="70%" />

(통계와 확률의 원리, 2017)

공분산<sup>covariance</sup>은 두 변수가 각각 평균에서 얼마나 멀리 떨어져 있는지를 나타낸다. 성햠 점수 매칭법 <sup>propensity score matching</sup>으로 다수의 공변량 <sup>covariate</sup>으로 성향 점수를 계산할 수 있다.

### 상관 계수<sup>correlation coefficient</sup>
상관 계수는 `r`로 표기한다. 상관의 정도를 나타내는 지표로 `-1`에서 `1` 사이의 값을 가지며, 방향<sup>direction</sup>과 강도 두 가지 정보를 제공한다. 0이면 강도가 낮다. 골턴의 제자인 피어슨(1857 ~ 1936)이 계산 방법을 고안했다.

<img width="70%" src="https://user-images.githubusercontent.com/1250095/34035241-c6f55932-e1c4-11e7-8ef7-b07999e62088.jpeg" />  

(수학 없이 배우는 데이터 과학과 알고리즘, 2017)

<img src="https://user-images.githubusercontent.com/1250095/47555930-164fc780-d948-11e8-8cad-295da5d56c47.jpeg" width="70%" />

## 거짓 상관
**Spurious relationship** 일본에서는 '의사 상관'이라고 하는데 '거짓 상관'으로 번역하는게 맞을 것 같다. 두 사건이 실제로는 관련이 없는데 우연의 일치, 보이지 않는 제3의 요소의 존재<sup>the presence of a certain third, unseen factor</sup>로 인과 관계가 있는 것으로 추측되는 것을 말한다. unseen factor는 "common response variable", confounding factor<sup>교란 요인</sup> 또는 "lurking variable"로 부르기도 한다. 또는 '제3의 변수'. (원인과 결과의, 경제학, 2018)는 제4의 변수, 조작 변수로 언급하기도 했다.

피어슨은 이 현상을 가짜 상관이라 불렀다. (통계학을 떠받치는 일곱기둥 이야기, 2016)

상관계수는 선형적인 상관관계만 측정합니다(x가 증가하면 y는 증가하거나 감소합니다). 그래서 비선형적인 관계는 잡을 수 없습니다. (핸즈온 머신러닝, 2017)

### 잠재 변수<sup>latent variables</sup>를 간파할 수 있는가?
- 40대에 출산한 여성은 장수하는 경향이 있다. 100세 이상의 여성들과, 73세에 사망한 여성들을 비교하면, 장수하는 여성들에서 고령 출산의 비율이 높았다. (1997년 nature 논문을 바탕으로 작성)
  - 40세에 출산할 수 있을 정도로 건강하며, 그래서 장수할 수 있었다. 잠재 변수: 건강 (통계와 확률의 원리, 2017)

## 부트스트래핑<sup>Bootstrapping</sup>
무작위 샘플링을 대체하여 수행되는 테스트 또는 메트릭이다. 부트스트랩은 인위적인 자료 집합을 만들어내는 컴퓨터를 이용해야 하는 몇 가지 방법 중에서 가장 탁월한 것이다. 하버드의 통계학자 퍼시 디아코니스는 에프론 박사의 기술은 "매우 간단하지만 상당히 효과적"이라고 말했다. (뉴욕타임스 수학, 2013, 1988년 기사)

## 편찻값
<img width="456" src="https://user-images.githubusercontent.com/1250095/32547348-55ed707e-c4c5-11e7-8ba8-3c1defd0bc49.png">

평균일때 50을 가르키는 일본어 *hensachi*([편차치](https://namu.wiki/w/%ED%8E%B8%EC%B0%A8%EC%B9%98))로 일본에서 출판된 통계학 책에만 등장하며 일본에서만 주로 쓰인다. 나무위키에 따르면 수능 학력 편차치로 쓰인다고. 영어로는 deviation value의 의미이고 영어권에서는 사용하지 않는다.

## 회귀<sup>regression</sup>
골턴은 1889년 『자연적 유전』 에서 회귀<sup>regression</sup>라는 개념을 논했다. 키가 큰 사람과 키가 작은 사람이 만나 아이를 낳으면 자녀들의 평균 키는 중간값, 즉 부모의 평균 키여야 했다. 이후 세대들이 이어지면서, 분산은 크게 변하지 않고 원상태를 유지하는 한편 평균 키는 고정된 중간값으로 '회귀'한다. (세계를 바꾼 17가지 방정식, 2011) '평균으로의 회귀'

## 편향<sup>bias</sup>
생존 편향<sup>Survivorship Bias</sup>  
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/98/Survivorship-bias.png/1024px-Survivorship-bias.png" width="50%" /> 

2차 세계대전 당시 통계학자 아브라함 발드가 살아남은 것만 주목하고 실패한 것은 고려하지 않는 '생존 편향'의 문제점을 지적했다. (틀리지 않는법, 2015)

[Science Isn’t Broken](https://fivethirtyeight.com/features/science-isnt-broken/) 연구자들은 주장하는 명제에 부합하는 통계를 산출하기 마련이다. 위와 비슷한 이야기. 미려한 이미지가 인상적이다.

연구자들은 환자들이 날씨의 어떤 면을 고려하든지 관절염 환자의 증상과 날씨 사이에서 아무 연관성을 발견하지 못했다. (뉴욕타임스 수학, 2013, 1996년 기사) 농구에서 핫 핸드가 근거 없는 믿음이라는 것과 마찬가지다.

통계학이 재판소에서 이용될때 그 영향이 진실을 호도하기 쉽다. 믈로디노프는 O.J 심슨 재판을 회상한다. 검사는 피고 심슨을 상습적인 아내 학대자로 묘사했다. 하지만 미국에서 해마다 4백만 명의 여성이 남편에게 구타를 당한다. 그 중 남편에게 살해되는 사람은 2,500분의 1에 불과하다. 배심원단은 설득력 있는 변론이라고 보았지만, 겉으로만 그럴싸한 논거다. 니콜 브라운 심슨은 이미 죽었다. 이 사건에 대한 적절한 질문은 살해당한 모든 피해 여성의 몇 퍼센트가 학대자에 의해서 죽느냐는 것이다. 믈로디노프가 주목한건 재판에서 그 답이 나오지 않았다는 점이다. 답은 90%였다. 이런 종류의 수학에서 변호사들은 의사들과 별 다를바 없는 것 같다. 하지만 배심원단의 수준은 더 심각하다. (뉴욕타임스 수학, 2013, 2008년 기사)

## 실험 계획법
피셔의 3원칙 <sup>basic principles of experimental designs</sup>
1. 반복 <sup>replication</sup>
1. 무작위화 <sup>randomization</sup>
1. 국소관리 <sup>local control</sup>

국소관리란 공간적, 시간적인 실험의 장을 작게 나누고, 그 속에서 실험을 실시하고 분석하는 것을 말한다. (통계학 도감, 2017)

## 기타
이산형 <sup>discrete</sup>, 연속형 <sup>continuous</sup>에서 이산형은 sum, 연속형은 적분 <sup>integral</sup>이 된다.

인과 관계 <sup>correlation</sup>에 불과한데도 상관 관계 <sup>causality</sup>로 혼동하는 경우가 있다. 둘 사이의 명확한 구분이 필요하다. (원인과 결과의, 경제학, 2018)

'건강검진을 받았기 때문에 장수할 수 있는 것(인과관계)'이 아니라, '건강검진을 받을 정도로 건강에 대한 의식이 높은 사람일수록 장수하는 것(상관관계)'으로 해석하는 것이 타당할 수 있다. (원인과 결과의, 경제학, 2018)

이중차분법 <sup>differences in differenses; DID</sup>은 두 집단의 difference를 difference한 두 시기로 비교해보는 것이다. 보통 정책 시행 전후로 수혜 집단과 비수혜 집단의 차이를 비교해보는데 쓰인다. ([출처](https://igija.tistory.com/270))

카드 카운팅을 발명한 에드워드 소프. 경우의 수 <sup>number of cases</sup>에서 카드 카운팅은 계산하기가 조금 복잡한 편이다. (넘버스, 2017)

# 분포
<img src="https://user-images.githubusercontent.com/1250095/47555931-164fc780-d948-11e8-813d-89753f1f0f76.jpeg" width="60%" />

- 정규 분포  
[누적 분포(cdf; cumulative distribution)를 그래프로 그려 실제값(actual ratio)가 얼마나 비슷한지 직접 도식화](https://nbviewer.jupyter.org/github/likejazz/jupyter-notebooks/blob/master/gaussian-distribution.ipynb) 했다.

![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Standard_deviation_diagram.svg/400px-Standard_deviation_diagram.svg.png)

확률 밀도 함수 <sup>pdf; Probability density function</sup> 즉, 적분값이 확률이 된다. 6시그마 활동이란 6$${\sigma}$$구간의 밖. 즉, 100만분의 3.4 수준으로 불량품을 줄이려는 활동을 말하며, 1980년대 후반 미국 모토롤라 연구진이 경영과 품질개선의 일환으로 시작했다. (통계학 도감, 2017)

- 이산 확률 분포<sup>discrete probability distribution</sup>  
확률 변수가 정해진 값을 갖고 있을때. 주어진 구간에서 어떠한 실수 값이라도 가질 수 있는 경우 continuous probability distribution<sup>연속 확률 분포</sup>이다.

- 이항 분포<sup>Binomial distribution</sup>  
> 시행(trial)에는 매우 전형적인 형태가 있어서 어떤 시행은 특별한 이름을 가지고 있다. 베르누이 시행(Bernoulli trial)이 그 중에 하나인데, 이를 처음 이야기한 통계학자의 이름을 따와 지었다. 이 시행의 특징은 그 결과가 단 두 가지 밖에 없다는 점이다. 동전 던지기가 베르누이 시행의 가장 대표적인 예다. ([온라인 게임에서의 이항 분포](http://www.boxnwhis.kr/2015/05/21/binomial_dist_in_games.html))

성공이나 실패처럼 결과가 두 종류밖에 없는 시행을 베르누이 시행이라고 한다.

- 균등 분포 <sup>uniform distribution</sup>  
각 사상이 일어나는 확률이 같은 분포

- 기하 분포<sup>Geometric distribution</sup>  
베르누이 시행에서 처음 성공까지 시도한 횟수 X의 분포 또는 실패한 횟수 Y=X-1의 분포. 대개의 경우 X의 분포를 가리키는 것이 일반적이다.

- 포아송 분포<sup>Poisson distribution</sup>  
시행 <sup>trial</sup> 횟수가 아주 많고(n이 크다), 사상 <sup>event</sup> 발생의 확률(p)이 아주 작을때의 이항 분포다. [런던 대공습의 폭탄이 정밀 타격인지 분석 결과, 푸아송 분포를 따랐다.](https://statkclee.github.io/statistics/stat-flying-bomb-poisson.html) (신은 주사위 놀이를 하지 않는다, 2014)

# 평균의 종류
10, 90이 있을때
- 산술 평균 <sup>arithmetic mean</sup>: 50
- 기하 평균 <sup>geometric mean</sup>: $$\sqrt{(10\times 90)} = 30$$
- 제곱 평균 <sup>root mean square; rms</sup>: $$\sqrt{\frac{10^2+90^2}{2}} = 64.03$$
- 조화 평균 <sup>harmonic mean</sup>: $$\frac{2}{\frac{1}{10} + \frac{1}{90}} = 18$$

## 조화 평균
수학에서 **조화 평균** <sup>harmonic mean</sup>은 주어진 수들의 역수의 산술 평균의 역수를 말한다. 평균적인 변화율을 구할 때에 주로 사용된다. (위키피디어) 서로 다른 거리를 정규화<sup>normalize</sup>하는 효과가 있다.

<img src="https://user-images.githubusercontent.com/1250095/45733499-faa42380-bc1b-11e8-9dc5-5cf66d994790.jpeg" width="70%" />  

(통계학 도감, 2017)

# Books
## 통계학을 떠받치는 일곱기둥 이야기 <sub>2016</sub>
**1. Aggregation: From Tables and Means to Least Squares**  
자료 집계: 표와 평균에서 최소 제곱법까지
- Variations of the Needle 자침 편차
- Aggregation in Antiquity 고대의 자료 집계
- The Average Man 평균 인간
- Aggregation and the Shape of the Earth 자료 집계와 지구 모양

조화 평균<sup>harmonic mean</sup>은 산술 평균<sup>arithmetic mean</sup>의 역수다.

최빈값<sup>mode</sup>은 가장 많이 나타나는 값이다.

**2. Information: Its Measurement and Rate of Change**  
정보 측정: 정보 측정과 변화율

- The Trial of the Pyx 주화 표본 검정  
검정용으로 쓸 주화를 몇 개씩 골라 픽스<sup>Pyx</sup>라 부르는 상자에 넣었다.
- Abraham de Moivre 아브라함 드 무아브르  
드 무아브르는 오늘날 이항 분포에 대한 정규 근사라 부르는 유명한 결과를 1733년에 도출하지만, 벌써 1730년에 분포의 결정적 측면이 n의 제곱근 편차와 엮여 있다는 것을 알았다. 드 무아브르는 개별 관측이나 관측 오차가 오떤 분포를 따르든 주화 표본의 무게 측정 같은 관측의 합계나 평균이 정규 분포를 따르리라는 같은 결론에 이르렀다. 증명이 철저하지 못한 데다, 1824년에는 푸아송이 오늘날 코시 분포라 부르는 예외 사례를 찾아냈다.
- Refinements, Extensions, and Paradoxes 개량, 확장, 역설

**3. Likelihood: Calibration on a Probability Scale**  
가능도: 확률 척도의 보정

- Arbuthnot and Significance Tests 아버스넷과 유의성 검정
- Hume, Price, and Bayesian Induction 흄, 프라이스, 베이즈의 귀납법
- Laplacian Testing 라플라스 검정
- A Theory of Likelihood 가능도 이론

**4. Intercomparison: Within-Sample Variation as a Standard**  
상호 비교: 표본 내 변동을 표준으로  
통계적으로 비교할 때 외부 기준을 참조하거나 믿지 말고 철저히 자료 내부에 있는 변동만으로 비교해야 한다는 발상이다.

- Gosset and Fisher’s t 고셋과 피셔의 t  
기네스에 근무하던 고셋이 스튜던트라는 가명으로 t 검정을 발표
- Francis Edgeworth and Two-Way Analyses for Variance Components 프랜시스 에지워스와 분산 요소에 대한 이원 분석  
에지워스는 오늘날 분산 성분이라 부르는 것을 추정하는 방법으로 자신의 분석을 구상했다.
- Some Pitfalls of Intercomparison 상호 비교의 함정

**5. Regression: Multivariate Analysis, Bayesian Inference, and Causal Inference**  
회귀: 다변량 분석, 베이즈 추론, 인과 관계 추론

- The Road from Darwin to Galton’s Discovery 다윈에서 골턴의 발견으로 가는 길
- Galton’s Interpretation 골턴의 해석
- The Solution to Darwin’s Problem 다윈의 문제를 푸는 해법
- Consequences 결과
- Multivariate Analysis and Bayesian Inference 다변량 분석과 베이즈 추론
- Bayesian Inference 베이즈 추론
- Shrinkage Estimation 축소 추정
- Causal Inference 인과 추론
- The Rule of Three: R.I.P. 비례법, 평화롭게 잠들다

**6. Design: Experimental Planning and the Role of Randomization**  
설계: 실험 계획과 랜덤화의 역할

- Additive Models 가법 모형
- Randomization 랜덤화

**7. Residual: Scientific Logic, Model Comparison, and Diagnostic Display**  
잔차: 과학 논리, 모형 비교, 진단 표시

- Diagnostic and Other Plots 진단과 다른 그림들

## 좋은 선택, 나쁜 선택 <sub>2019</sub>
- 데이터에 기반한 선택이 좋은 선택이다  
선택의 방법에는 경험, 개연성, 영도에 따른, 다수의 선택 등 다양한 방법이 있지만 데이터에 기반한 선택이 최선이다.
- 우리의 수치에 대한 직관은 믿을 만하지 않다  
생일이 겹치는 문제, 몬티 홀 문제와 같은 대표적인 확률을 잘못 계산하는 문제가 나온다. 교양 통계 서적을 자주 봤다면 한번쯤 봤을 내용.
- 확률과 통계의 함정  
독립 사건: 9번 모두 동전 앞면이 나와도 10번째에 앞면이 나올 확률은 1/2이다. 큰 수의 법칙과 이항 분포로 동전이 몇 번이나 나올지에 대한 확률을 계산할 수 있다. 1733년에 드 무아브르는 이항 분포의 시행 횟수를 크게 하면 종 모양의 분포로 근사시킬 수 있다고 주장했다. 이 분포는 지금의 정규 분포인 종 모양을 가진다. p.65 18세기 말 프랑스의 수학자 라플라스는 전체 사건이 어떤 확률 분포를 따르든 간에 표본을 뽑은 후 그 본의 평균을 구하면, 표본의 개수 n이 적당히 크기만 하다면 이 표본의 평균이 전체 사건의 집합인 모집단의 평균값을 중심으로 하는 정규 분포를 이룬다는 중심극한정리를 발표했다. p.66 
- 데이터 수치가 말하지 않는 것  
정확도와 재현율에 대해 언급하는데, 이 보다는 표본집단 <sup>sample</sup>에 대한 확률의 함정에 대해 다룬다. 모집단 <sup>population</sup>을 대표하는 표본 추출이 편향되게 <sup>bias</sup> 추출되지 않는게 중요하다. 생존 편향의 얘기도 나온다.
- 거짓말은 아닙니다  
윤리, 데이터를 부풀려 표현하는 문제, 5% p-value의 함정, 재현 불가에 대해 얘기한다.
- 숫자로 쌓아 올린 신기루  
[화물숭배](https://ko.wikipedia.org/wiki/%ED%99%94%EB%AC%BC%EC%88%AD%EB%B0%B0%EA%B3%BC%ED%95%99) <sup>Cargo Cult</sup>  
현대 사회에서 누군가에게 주술을 믿느냐고 물으면 대부분 얼굴을 붉히며 자신을 모욕하지 말라고 항의할 것이다. 그런데 아이러니한 것은 주술을 사용하여 자기 계발을 전파하는 책에 대해서는 극찬하면서 자신의 삶을 바꾸는 지표로 삼는다는 사람을 쉽게 찾아볼 수 있다는 점이다. p.132
- 선택을 해봅시다  
'엘리베이터에서 배우자 고르기'는 『알고리즘, 인생을 계산하다』에 나온 37% 문제와 유사.
- 합리적인 선택을 위해 해야 할 일  
데이터 시각화가 중요하다고 강조.
